{
 "cells": [
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using BenchmarkTools"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Row/Column-major\n",
    "Different programming languages use different memory layouts for arrays. For example matrices are stored in\n",
    "row-major format in C/C++, Rust or Python; whereas they are stored in column-major format in Julia, Fortran and MATLAB.\n",
    "Because of how data of these matrices is cached when we perform operations on them, the order in which we access the data\n",
    "is important in terms of performance. In Julia we always want to iterate over the inner most index first, so we acces the arrays\n",
    "memory contiguously and avoid cache misses"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  273.375 μs (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "n = 256\n",
    "A, B, C = rand(n,n), rand(n,n), rand(n,n)\n",
    "function row_major!(A, B, C)\n",
    "    for i in axes(A, 1), j in axes(A, 2)\n",
    "        A[i, j] = B[i, j] * C[i, j]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "@btime row_major!($A, $B, $C);"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  14.584 μs (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "function column_major!(A, B, C)\n",
    "    for j in axes(A, 2), i in axes(A, 1)\n",
    "        A[i, j] = B[i, j] * C[i, j]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "@btime column_major!($A, $B, $C);"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Julia does biunds checking by default, but you can turn it off with the macro `@inbounds`,\n",
    "usually resulting in faster code"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  14.542 μs (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "function column_major_inbounds!(A, B, C)\n",
    "    @inbounds for j in axes(A, 2), i in axes(A, 1)\n",
    "        A[i, j] = B[i, j] * C[i, j]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "@btime column_major_inbounds!($A, $B, $C);"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stack vs Heap allocation\n",
    "These are the places in the memory where data is \"stored\". The stack is statically allocated and it is ordered.\n",
    "This order allows the compiler to know exactly where things are, yielding very quick access. Like everything else that is referred as static\n",
    "the size of variables (i.e. type and length) has to be known at compile time. On the other hand, the heap is dynamically allocated, and not necessarily is unordered, resulting in slower acces.\n",
    "An excellent explanation of the difference between stack and heap can be found in [Rust's docs](https://web.mit.edu/rust-lang_v1.25/arch/amd64_ubuntu1404/share/doc/rust/html/book/first-edition/the-stack-and-the-heap.html)."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  16.867 ns (1 allocation: 80 bytes)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2-element Vector{Float64}:\n 0.6504407092201697\n 0.9554583092089126"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "allocate_heap() = [rand(); rand()]\n",
    "@btime allocate_heap() # data size is a runtime parameter (~malloc)"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.750 ns (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.6736190105959982, 0.6820469885862294)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "allocate_stack() = (rand(), rand()) # a tuple of two floats, everything is known at compile time\n",
    "@btime allocate_stack()"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "A very good performance-wise trick if we want to create non-allocating array-like objects is to use StaticArrays.jl"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.750 ns (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2-element StaticArraysCore.SVector{2, Float64} with indices SOneTo(2):\n 0.5553233997388317\n 0.2683469755745207"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "using StaticArrays\n",
    "allocate_SA() = @SVector [rand(); rand()] # a tuple of two floats, everything is known at compile time\n",
    "@btime allocate_SA()"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# In-place vs out-of-place\n",
    "It is common that you need to store the results of matrix operations in a new array. Creating the new destination array will obviously allocate, if you need to this operation just once, an out-of-place kernel will do just fine"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  263.500 μs (2 allocations: 512.05 KiB)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "256×256 Matrix{Float64}:\n 0.0244012    7.58547e-5   7.46491e-10  …  1.81869e-5   0.0653567\n 0.0020739    8.54529e-16  8.48845e-7      7.97624e-13  7.98994e-6\n 2.68162e-12  3.06088e-17  6.56965e-8      1.73457e-17  0.430133\n 1.03756e-8   0.56313      0.00152206      1.857e-14    1.40048e-6\n 5.51295e-7   4.75049e-8   0.00770729      2.40125e-11  0.0919725\n 6.27639e-34  8.7353e-22   6.78255e-5   …  2.30061e-12  9.85281e-14\n 2.95727e-17  2.54384e-16  9.05094e-12     0.000604221  0.000291508\n 1.83778e-17  4.5415e-15   1.40283e-12     0.0313915    0.240203\n 1.48995e-5   0.918037     0.00147836      2.19671e-6   3.4345e-21\n 1.23881e-38  3.36199e-6   5.22451e-12     1.61746e-7   1.55344e-7\n ⋮                                      ⋱               ⋮\n 1.73668e-5   3.63267e-19  5.55119e-26     2.77805e-12  0.0425412\n 2.02473e-21  1.2394e-32   0.000572216     8.17624e-8   1.59288e-8\n 6.63307e-5   2.09905e-6   3.98218e-6      8.71846e-8   1.5168e-5\n 0.0735741    3.47143e-6   1.3824e-17   …  6.55775e-10  5.55435e-18\n 2.2467e-13   3.69958e-6   1.23326e-5      0.00232282   0.108406\n 0.109915     3.28372e-13  6.11656e-8      9.58454e-5   5.47007e-11\n 1.11647e-15  5.03388e-5   1.96714e-7      5.41392e-8   1.0285e-19\n 0.000842883  4.34637e-14  4.69626e-37     0.000483058  2.20007e-10\n 1.85615e-11  1.2116e-7    3.64915e-5   …  0.115719     4.70813e-10"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "function outofplace(A, B)\n",
    "    C = similar(A)\n",
    "    for i in axes(A, 1), j in axes(A, 2)\n",
    "        C[i, j] = B[i, j] * C[i, j]\n",
    "    end\n",
    "    return C\n",
    "end\n",
    "@btime outofplace($A, $B)"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "however, it is frequent you need to run the kernel several times, in which case you want to avoid allocating the destination array every time. In this case, you can use an in-place kernel, by pre-allocating the destinating array and just mutating it:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  272.167 μs (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "function inplace!(C, A, B)\n",
    "    for i in axes(A, 1), j in axes(A, 2)\n",
    "        C[i, j] = B[i, j] * C[i, j]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "@btime inplace!($C, $A, $B)"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "note that in the latter case we do no return anything, as Julia passes arguments by reference to the functions.\n",
    "Also note the `!` at the end for the in-place function, this is a convention in Julia to denote that the function mutates its arguments (where the mutating arguments are the first ones)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Array-like programming\n",
    "# # Broadcasting\n",
    "As in MATLAB, Julia allows to perform element-wise operations on arrays, this is called broadcasting. A dot before the target function indicates broadcasting"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  19.708 μs (2 allocations: 512.05 KiB)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "256×256 Matrix{Float64}:\n 1.69851    1.08498    0.874138   …  0.609179    0.708098  1.60865\n 0.836012   0.366645   0.778152      0.387308    0.391743  0.88397\n 0.714155   0.502699   0.693197      0.151027    0.361749  1.26867\n 0.733409   1.73723    1.50097       1.61266     0.33491   0.726234\n 0.802293   0.936798   0.992722      1.00761     0.736017  1.47277\n 0.0678015  0.310121   1.20864    …  0.66941     0.791522  0.519745\n 0.32115    0.39483    0.676584      1.02473     0.854787  1.24166\n 0.291325   0.518057   0.444003      0.00195173  1.08073   1.15083\n 1.20707    1.32184    1.4376        0.146819    0.961329  0.3307\n 0.0652999  1.22418    0.489674      0.0878365   0.618127  0.957436\n ⋮                                ⋱                        ⋮\n 0.998101   0.24874    0.132507      0.941759    0.561101  1.45079\n 0.177123   0.0685122  1.56097       0.448772    0.76174   0.661713\n 1.06105    1.17676    1.02949       0.0738419   0.869964  0.720023\n 1.46343    0.942578   0.471918   …  0.0026523   0.615337  0.438549\n 0.455235   1.05298    1.25765       0.492313    1.24121   1.22237\n 1.67198    0.442705   0.668121      0.72145     1.36584   0.492804\n 0.580413   1.19007    1.23734       0.144075    0.736875  0.208836\n 1.16398    0.367018   0.0686989     1.43924     1.23882   0.540435\n 0.476681   0.652395   1.423      …  1.31        1.1218    0.716808"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "broadcast1(A, B, C) = A .+ B .+ C\n",
    "@btime broadcast1($A, $B, $C)"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "alternative you can use the macro `@.` to remove dot redundancy and apply broadcasting to all the operations"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  19.708 μs (2 allocations: 512.05 KiB)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "256×256 Matrix{Float64}:\n 1.69851    1.08498    0.874138   …  0.609179    0.708098  1.60865\n 0.836012   0.366645   0.778152      0.387308    0.391743  0.88397\n 0.714155   0.502699   0.693197      0.151027    0.361749  1.26867\n 0.733409   1.73723    1.50097       1.61266     0.33491   0.726234\n 0.802293   0.936798   0.992722      1.00761     0.736017  1.47277\n 0.0678015  0.310121   1.20864    …  0.66941     0.791522  0.519745\n 0.32115    0.39483    0.676584      1.02473     0.854787  1.24166\n 0.291325   0.518057   0.444003      0.00195173  1.08073   1.15083\n 1.20707    1.32184    1.4376        0.146819    0.961329  0.3307\n 0.0652999  1.22418    0.489674      0.0878365   0.618127  0.957436\n ⋮                                ⋱                        ⋮\n 0.998101   0.24874    0.132507      0.941759    0.561101  1.45079\n 0.177123   0.0685122  1.56097       0.448772    0.76174   0.661713\n 1.06105    1.17676    1.02949       0.0738419   0.869964  0.720023\n 1.46343    0.942578   0.471918   …  0.0026523   0.615337  0.438549\n 0.455235   1.05298    1.25765       0.492313    1.24121   1.22237\n 1.67198    0.442705   0.668121      0.72145     1.36584   0.492804\n 0.580413   1.19007    1.23734       0.144075    0.736875  0.208836\n 1.16398    0.367018   0.0686989     1.43924     1.23882   0.540435\n 0.476681   0.652395   1.423      …  1.31        1.1218    0.716808"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "cell_type": "code",
   "source": [
    "broadcast2(A, B, C) = @. A + B + C\n",
    "@btime broadcast2($A, $B, $C)"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "See that we are still allocating an output array. We can also do in-place operations with broadcasting by putting a dot before the equal symbol"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  12.917 μs (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "function broadcasting3!(C, A, B)\n",
    "    C .= A .+ B\n",
    "    return nothing\n",
    "end\n",
    "@btime broadcasting3!($C, $A, $B);"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "# # Array slicing\n",
    "We can use MATLAB syntax to slice our arrays"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Aslice = A[:, 1];"
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, this is creating a new array out of the slice of A (=allocating). If we want to avoid this, we can use the `@view` macro"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  388.198 ns (2 allocations: 4.25 KiB)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "256-element view(::Matrix{Float64}, :, 1) with eltype Float64:\n 1.6985075371481333\n 0.8360120260447305\n 0.7141553882420562\n 0.7334093492375442\n 0.8022927112845272\n 0.06780153724454925\n 0.32115038479883007\n 0.2913251116973369\n 1.207071041922602\n 0.06529989791887418\n ⋮\n 0.9981006336701361\n 0.1771226671547133\n 1.0610539308661615\n 1.4634349892443776\n 0.4552349499243\n 1.67197766810527\n 0.580413430831008\n 1.1639767251294675\n 0.47668092370174275"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "cell_type": "code",
   "source": [
    "@btime @. $C[:, 1] = $A[:, 1] + $B[:, 1]"
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "But we can avoid allocations using the `@views` macro"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  36.421 ns (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "256-element view(::Matrix{Float64}, :, 1) with eltype Float64:\n 1.6985075371481333\n 0.8360120260447305\n 0.7141553882420562\n 0.7334093492375442\n 0.8022927112845272\n 0.06780153724454925\n 0.32115038479883007\n 0.2913251116973369\n 1.207071041922602\n 0.06529989791887418\n ⋮\n 0.9981006336701361\n 0.1771226671547133\n 1.0610539308661615\n 1.4634349892443776\n 0.4552349499243\n 1.67197766810527\n 0.580413430831008\n 1.1639767251294675\n 0.47668092370174275"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "cell_type": "code",
   "source": [
    "@btime @views @. $C[:, 1] = $A[:, 1] + $B[:, 1]"
   ],
   "metadata": {},
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tip: loops are *fast*, so just loop. Looping often yields faster code, as you can do\n",
    "more optimizations (e.g. loop fusion, caching, loop unrolling, SIMD, etc.), and more readible code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  },
  "kernelspec": {
   "name": "julia-1.9",
   "display_name": "Julia 1.9.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}

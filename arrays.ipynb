{
 "cells": [
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using BenchmarkTools"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Working with Arrays\n",
    "Imagine that for some obscure reason we want to do a reduction\n",
    "of saxpy kernel ($A_{ij} * B_{ij} + C_{ij}$) on the interior of a 2D array (i.e. excluding the boundaries)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "n = 256\n",
    "A, B, C = rand(n,n), rand(n,n), rand(n,n)\n",
    "f(A, B, C) = sum(A[2:end-1, 2:end-1] .* B[2:end-1, 2:end-1] .+ C[2:end-1, 2:end-1]);"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "which reads as MATLAB. Let's benchmark it"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  136.209 μs (8 allocations: 1.97 MiB)\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "@btime f($A, $B, $C);"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "not very impressive. Let's try to make it faster in a Julia way with a one-liner"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  74.625 μs (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "f1(A, B, C) = sum(A[i, j] * B[i, j] + C[i, j] for i in axes(A,1)[2:end-1], j in axes(A,2)[2:end-1])\n",
    "@btime f1($A, $B, $C);"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "not bad, we cut off 50% of the time. Unlike Python and MATLAB, loops in Julia are **fast** (and lead to more readible code),\n",
    "so we can further speed up things if we are willing to type a bit more"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  55.166 μs (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "function f2(A, B, C)\n",
    "    v = 0.0\n",
    "    nx, ny = size(A)\n",
    "    for j in 2:ny-1, i in 2:nx-1\n",
    "        v += A[i, j] * B[i, j] + C[i, j]\n",
    "    end\n",
    "    return v\n",
    "end\n",
    "@btime f2($A, $B, $C);"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "that's already a x2.5 speedup. Beyond this point, the optimizations are less language-based and more algorithm-based.\n",
    "For example, we could improve the spatial locality of the function by introducing loop unrolling to a given depth (which has to be known at compile time)"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  27.541 μs (0 allocations: 0 bytes)\n",
      "  17.416 μs (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "function f4(A, B, C, ::Val{N}) where N\n",
    "    v = 0.0\n",
    "    nx, ny = size(A)\n",
    "    blocks = div(nx, N)\n",
    "    stride = N\n",
    "    for j in 2:ny-1\n",
    "        for i in 2:stride:((blocks-1)*stride)-1\n",
    "            A0 = ntuple(Val(N)) do ix\n",
    "                Base.@_inline_meta\n",
    "                @inbounds A[ix+i-1, j]\n",
    "            end\n",
    "            B0 = ntuple(Val(N)) do ix\n",
    "                Base.@_inline_meta\n",
    "                @inbounds B[ix+i-1, j]\n",
    "            end\n",
    "            C0 = ntuple(Val(N)) do ix\n",
    "                Base.@_inline_meta\n",
    "                @inbounds C[ix+i-1, j]\n",
    "            end\n",
    "            @inbounds v += sum(muladd(A0[k], B0[k], C0[k]) for k in 1:N)\n",
    "        end\n",
    "        @inbounds v += sum(muladd(A[i, j], B[i, j], C[i, j]) for i in (((blocks-1)*stride)-1 + stride):nx-1)\n",
    "    end\n",
    "\n",
    "    return v\n",
    "end\n",
    "\n",
    "@btime f4($A, $B, $C, Val(2)); # 27.554\n",
    "@btime f4($A, $B, $C, Val(4)); # 17.458"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "for a x5-8 speed up. Or if we are willing to accept some black magic\n",
    "we can use `LoopVectorization.jl` to effortlessly vectorize the loop"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  23.708 μs (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using LoopVectorization\n",
    "function f3(A, B, C)\n",
    "    v = 0.0\n",
    "    nx, ny = size(A)\n",
    "    @turbo for j in 2:ny-1, i in 2:nx-1\n",
    "        v += A[i, j] * B[i, j] + C[i, j]\n",
    "    end\n",
    "    return v\n",
    "end\n",
    "@btime f3($A, $B, $C);"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "for a nice simpler x6 speedup."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0-rc1"
  },
  "kernelspec": {
   "name": "julia-1.10",
   "display_name": "Julia 1.10.0-rc1",
   "language": "julia"
  }
 },
 "nbformat": 4
}
